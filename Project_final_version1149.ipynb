{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3h-FO5r6WtHW"
   },
   "source": [
    "# Group information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zm7MkQUqXMvb"
   },
   "source": [
    "Group 3 (Project 1)\n",
    "\n",
    "Name (SID): \n",
    "\n",
    "- Lam Yee Chun (20538053)\n",
    "- Yeung Tsz Ching (20507377)\n",
    "- Ng Pak Nin (20517748)\n",
    "- Ng Hung Hing (20354823)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3t9zJ-audCyc"
   },
   "source": [
    "# Package installation & Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sV3T0yFc3Sw"
   },
   "source": [
    "####For Google colab (Comment all below cells for non colab users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-8tB0M7EdPAq",
    "outputId": "75c008fc-651b-4f79-c73b-76ceef6b16c6"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYc0FDeRdbaS"
   },
   "source": [
    "####Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVTY_0bQf-60"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import fbeta_score,precision_score,recall_score\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_ZPrD4pc7yP",
    "outputId": "5aa3b5f8-16b4-44ad-e542-379baa772fd2"
   },
   "outputs": [],
   "source": [
    "assert os.environ['COLAB_GPU'], 'Make sure to select GPU from Edit > Notebook settings > Hardware accelerator'\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3L8ka2elc_MN"
   },
   "outputs": [],
   "source": [
    "!rm -f data\n",
    "!ln -s '/content/drive/My Drive/proj1_data' proj1_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Escghku1eMv9"
   },
   "source": [
    "####Dataset with data augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZug_qy_ePNF"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    '''\n",
    "      usage:\n",
    "      train_set = MyDataset(train_folder, transform=train_transform)\n",
    "      val_set = MyDataset(val_folder, transform=val_transform)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, folders, transform=None):\n",
    "        self.folders, self.labels = self.get_labels(folders)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.folders)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        folder_id = self.folders[idx]\n",
    "        \n",
    "        try:\n",
    "            with open(folder_id, 'rb') as f:\n",
    "                color_img = pickle.load(f)\n",
    "        except EOFError:\n",
    "            print(folder_id)\n",
    "\n",
    "        # img process\n",
    "        for i in range(color_img.shape[0]):\n",
    "            if np.ptp(color_img[i, :, :]) != 0:\n",
    "                color_img[i,:,:] = (color_img[i,:,:] - np.min(color_img[i,:,:])) / np.ptp(color_img[i,:,:])\n",
    "        color_img = color_img.transpose((1,2,0))\n",
    "\n",
    "        # img process\n",
    "        c1 = color_img[:,:,0]\n",
    "        c2 = color_img[:,:,1]\n",
    "        c3 = color_img[:,:,2]\n",
    "        c4 = color_img[:,:,3]\n",
    "        \n",
    "        c1 = np.expand_dims(c1, axis=2)\n",
    "        c2 = np.expand_dims(c2, axis=2)\n",
    "        c3 = np.expand_dims(c3, axis=2)\n",
    "        c4 = np.expand_dims(c4, axis=2)\n",
    "\n",
    "        color_img = np.concatenate((c1, c2, c3, c4), axis=2)\n",
    "        for i in range(color_img.shape[2]):\n",
    "            if np.ptp(color_img[:,:,i]) == 0:\n",
    "                continue\n",
    "            color_img[:,:,i] = (color_img[:,:,i] - np.min(color_img[:,:,i])) / np.ptp(color_img[:,:,i])\n",
    "\n",
    "        # img process, tranform\n",
    "        if self.transform is not None:\n",
    "            color_img = np.uint8(255*color_img)\n",
    "            color_img = Image.fromarray(color_img)\n",
    "            color_img = self.transform(color_img)\n",
    "\n",
    "        return color_img, self.labels[idx]\n",
    "\n",
    "\n",
    "    def get_labels(self, folders):\n",
    "\n",
    "        files = []\n",
    "        labels = []\n",
    "        #class_num = []\n",
    "\n",
    "        #conding=utf8  \n",
    "        g = os.walk(folders)  \n",
    "\n",
    "        for path, _, file_list in g:  \n",
    "            for file_name in file_list:\n",
    "                files.append(os.path.join(path, file_name))\n",
    "                if 'nil_HS_H08' in file_name or 'light_HS_H08' in file_name:\n",
    "                    labels.append(0)\n",
    "                    #class_num.append(591)\n",
    "                elif 'moderate_HS_H08' in file_name:\n",
    "                    labels.append(1)\n",
    "                    #class_num.append(839)\n",
    "                else:\n",
    "                    labels.append(2)\n",
    "                    #class.num.append\n",
    "\n",
    "        return files, labels\n",
    "\n",
    "    def get_cls_num_list(self, folders):\n",
    "        _, class_list = self.get_labels(folders)\n",
    "        class_num_list = []\n",
    "        for i in range(3):\n",
    "            class_num_list.append(class_list.count(i)*3)\n",
    "        return class_num_list\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3JhTrMxGTNr"
   },
   "source": [
    "#### **Dataset load and basic data augmentation**\n",
    "\n",
    "\n",
    "> We initialize the training set and validation set as MyDataset and resize the data in the two sets to handle the data with different sizes. We also decided to normalize the data to bring them to a common scale and reduce variance to allow better model performance.\n",
    "\n",
    "\n",
    "> To ease the problem of overfitting, we have implemented a set of data augmentation strategies. We apply a data transformer which will randomly apply rotation, flipping and cropping. We chose not to include color jittering into the data transformer since it gives a worse training and validation performance by trials.\n",
    "\n",
    "\n",
    "> We tried doubling and tripling the dataset with transformed augmented data. By tripling the data size with the augmented data, it gives a higher validation accuracy and better reduction of the overfitting problem.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pIOX8yYzf3MK",
    "outputId": "cfa6545f-7477-4338-e95c-9fd36ec534d2"
   },
   "outputs": [],
   "source": [
    "#Dataset load and basic data augmentation\n",
    "\n",
    "#For non-colab\n",
    "#train_folder = 'train'\n",
    "#val_folder = 'validate'\n",
    "#---------------------#\n",
    "#For colab\n",
    "train_folder = 'train'\n",
    "val_folder = 'validate'\n",
    "#---------------------#\n",
    "\n",
    "resize_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5307, 0.4912, 0.5074, 0.5072), (0.2738, 0.2922, 0.2976, 0.2993))\n",
    "])\n",
    "train_smallset = MyDataset(train_folder, transform=resize_transform)\n",
    "val_set = MyDataset(val_folder, transform=resize_transform)\n",
    "\n",
    "###data augmentation\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.RandomApply([\n",
    "                transforms.RandomRotation(10), \n",
    "                transforms.RandomHorizontalFlip(), \n",
    "                transforms.RandomVerticalFlip(), \n",
    "                transforms.RandomCrop((150,150))\n",
    "            ]),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "all_datasets = []\n",
    "all_datasets.append(train_smallset)\n",
    "for i in range(2):\n",
    "    aug_train_set = MyDataset(train_folder, transform=aug_transform)\n",
    "    all_datasets.append(aug_train_set)\n",
    "train_set = torch.utils.data.ConcatDataset(all_datasets)\n",
    "print(\"train shape:\", train_set.__len__())\n",
    "print(\"val shape:\", val_set.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNO6oX3eilKV"
   },
   "source": [
    "#### Util Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UQTvOMvXMax"
   },
   "source": [
    "### Classification report Utility\n",
    "This is a ultility function for benchmarking the classification performance of a model on a given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1fEVlhOXIjp"
   },
   "outputs": [],
   "source": [
    "# classification report utility\n",
    "\n",
    "def evaluate(model, dataset):\n",
    "    data = DataLoader(dataset, batch_size=20, num_workers=4, shuffle=True)\n",
    "    Y_hat_list = torch.Tensor().cuda()\n",
    "    Y_list = torch.Tensor()\n",
    "    model.cuda()\n",
    "    for X, Y in data:\n",
    "        logits = model(X.cuda())\n",
    "        _, Y_hat = torch.max(logits, 1)\n",
    "        Y_hat_list = torch.cat((Y_hat_list, Y_hat), 0)\n",
    "        Y_list = torch.cat((Y_list, Y), 0)\n",
    "    print(classification_report(Y_list.cpu().numpy(), Y_hat_list.cpu().detach().numpy()))\n",
    "    return classification_report(Y_list.cpu().numpy(), Y_hat_list.cpu().detach().numpy(), output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xguM1k3sxcgi"
   },
   "source": [
    "### Image data preview utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3zdu0AB-xafQ"
   },
   "outputs": [],
   "source": [
    "def get_random_sample(dataset):\n",
    "  random.seed()\n",
    "  index = random.randrange(dataset.__len__())\n",
    "  sample_image,_ = dataset.__getitem__(index)\n",
    "  return sample_image, index\n",
    "\n",
    "def get_one_sample(dataset, index):\n",
    "  sample_image,_ = dataset.__getitem__(index)\n",
    "  return sample_image\n",
    "\n",
    "def plot_random(dataset):\n",
    "  sample_image,index = get_random_sample(dataset)\n",
    "  print('Sample index:', index,'Class:',train_Y[index])\n",
    "  for layers in range(4):\n",
    "    plt.subplot(2,2,layers+1)\n",
    "    title_obj  = plt.title(\"Layer %i\" % (layers + 1))\n",
    "    plt.tight_layout()\n",
    "    plt.setp(title_obj, color='w')\n",
    "    plt.imshow(sample_image[layers])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXgbeso0WO11"
   },
   "source": [
    "# Baseline 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPbqGDhuWsSs"
   },
   "source": [
    "*Strategy*\n",
    "\n",
    "####**Model Framework: PyTorch Lightning**\n",
    "We use PyTorch Lightning(https://www.pytorchlightning.ai) as our model framework because it allows us to modularize our code into dedecated steps and functions, enabling fast prototyping and expansion while maintaining readability.\n",
    "\n",
    "####**Model Structure: Convolutional neural network**\n",
    "Our model network consists of three parts: self defined convolutional layers, Resnet model,  fully connected layers\n",
    "\n",
    "####*Self defined convolutional layers:*\n",
    "As we are training data that are 4-band multispectral images, we defined one convolutional layer to extract 4-channel inputs into 3 feature maps. With a 3-channel output, we are able to pass the output to Resnet which requires a 3-band input.\n",
    "After trying adding 2 convolutional layers, we concluded that having one layer before the Resnet network gives the best result. After trying adding 2 convolutional layers, we concluded that having one layer before the Resnet network gives the best result. The following graph shows the training accuracy with the model using 2 conv layers can only reach around 70%, while our finalized baselines are able to obtain more than 75%.\n",
    "###*2 conv layer*\n",
    "###![2convlayer](graphs/2convlayer.jpeg)\n",
    "\n",
    "####*Resnet model:*\n",
    "We tried training our model with two different version of Resnet. \n",
    "As shown as below, although ResNet34 gives a better result in training performance, ResNet50 gives higher validation accuracy and lower loss.\n",
    "\n",
    "ResNet50 gives an average validation accuracy of 79%, which is 6% higher than ResNet34, which is 73% (see graph below).\n",
    "As we can see, a more complex ResNet yields a better result. From this hypothesis, we tried to test ResNet101, but the ust lab GPU runs out of memory for this model, so we settled on ResNet50.\n",
    "###*resnet34 vs resnet50*\n",
    "#####![resnet34 vs resnet50](graphs/resnet.jpeg)\n",
    "\n",
    "We use this pretrained ResNet model as a feature extracter for the images, so all layers of the resnet are freezed except the last fc layer, where we retrain it to classify our images into their corresponding three classes.\n",
    "\n",
    "####*Fully Connected layer:*\n",
    "We defined two FC layers after Resnet for classification.\n",
    "With Resnet outputting size 1000 output, the first FC layer allow input size 1000 and output 512.\n",
    "The second FC layer are used to classify the 512 sized input into size 3 output, which will undergo a softmax function. The size 3 output will be the modelâ€™s probability of predicting the 3 classes : SEV, MOD, NIL.\n",
    "We have tried using only one FC layer to classify the size 1000 input into 3 classes. However, the result yielded is not as good as using two FC layers.\n",
    "\n",
    "####*Optimizer:*\n",
    "We chose AdamW as the optimzer.\n",
    "We tried using SGD optimizer before, the following graphs shows the training accuracy only reach 50% while validation accuracy fluctuates and drops to 25%. Comparing to AdamW we are using in our finalized baseline1, SGD gives a very bad performance.\n",
    "### *SGD Optimizer Performance*\n",
    "####![SGDopt](graphs/SGDopt.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ud9NBaTGX5Bj"
   },
   "outputs": [],
   "source": [
    "class BL1(pl.LightningModule):\n",
    "    def __init__(self, lr = 0.05, oversample=False, verbose = False):\n",
    "        super(BL1, self).__init__()\n",
    "        self.oversample = oversample\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "        self.loss_func = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(4, 3, 5)\n",
    "        self.resnet = models.resnet50(pretrained = True)\n",
    "        \n",
    "        # freeze all layers in resnet\n",
    "        for parameter in self.resnet.parameters():\n",
    "            parameter.requires_grad = False\n",
    "        self.resnet.fc.requires_grad=True\n",
    "        \n",
    "        self.fc1 = nn.Linear(1000, 512)\n",
    "        self.fc2 = nn.Linear(512, 3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.resnet(x)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, target = batch\n",
    "        output = self.forward(images)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        acc = (target == preds).float().mean()\n",
    "        loss = self.loss_func(output,target)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc)\n",
    "        return {'loss': loss, 'acc': acc}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, target = batch\n",
    "        output = self.forward(images)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        acc = (target == preds).float().mean()\n",
    "        loss = self.loss_func(output,target)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc)\n",
    "        return {'loss': loss, 'acc': acc}\n",
    "\n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        loss_list = []\n",
    "        acc_list = []\n",
    "        for output in training_step_outputs:\n",
    "            loss_list.append(output[\"loss\"].item())\n",
    "            acc_list.append(output[\"acc\"].item())\n",
    "        if self.verbose:\n",
    "            print('train_loss:', sum(loss_list)/len(loss_list), 'train_acc:', sum(acc_list)/len(acc_list))\n",
    "        \n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        loss_list = []\n",
    "        acc_list = []\n",
    "        for output in validation_step_outputs:\n",
    "            loss_list.append(output[\"loss\"].item())\n",
    "            acc_list.append(output[\"acc\"].item())\n",
    "        if self.verbose:\n",
    "            print('        validation_loss:', sum(loss_list)/len(loss_list), 'validation_acc:', sum(acc_list)/len(acc_list))\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return optim.AdamW(self.parameters(), lr=self.lr)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        dataset = train_set\n",
    "        if self.oversample:\n",
    "            return DataLoader(dataset, batch_size=50, num_workers=8, sampler=ImbalancedDatasetSampler(dataset))\n",
    "        else:\n",
    "            return DataLoader(dataset, batch_size=50, num_workers=8, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = val_set\n",
    "        return DataLoader(dataset, batch_size=40, num_workers=8, shuffle=False)\n",
    "\n",
    "# Train Model\n",
    "\"\"\" \n",
    "model = BL1(lr=0.0002)\n",
    "trainer = Trainer(\n",
    "    gpus=1,\n",
    "    progress_bar_refresh_rate = 20,\n",
    "    callbacks=[EarlyStopping(\n",
    "          monitor='val_loss',\n",
    "          patience=30,\n",
    "        min_delta=0.00,\n",
    "        verbose=False\n",
    "      )],\n",
    "      num_sanity_val_steps=0\n",
    ")\n",
    "trainer.fit(model)\n",
    "model.eval()\n",
    "\"\"\"\n",
    "\n",
    "model = torch.load('model_bl1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6I8gHWa3XuNA"
   },
   "source": [
    "Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDWoBRtaX60H"
   },
   "source": [
    "Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wYHCQM_X0iN"
   },
   "outputs": [],
   "source": [
    "evaluate(model, train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzgWBi0gYAgf"
   },
   "source": [
    "Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWInRoUGYB0N"
   },
   "outputs": [],
   "source": [
    "evaluate(model, val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFiPcvI6X55i"
   },
   "source": [
    "# Baseline 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLlMRq8YsX5j"
   },
   "source": [
    "LDAM Loss\n",
    "\n",
    "The function modifies the model output by reducing output probability of the correct target class then put into the cross entropy loss. Which the LDAM loss will just affects the gradient of the data in a more involved way than only introducing a scalar weighting factor as the scalar introduced by LDAM loss also depends on the output of the model. \n",
    "\n",
    "- $L_{LDAM}((x,y);f) = -log\\frac{e^{z_y-\\Delta_y}}{e^{z_y-\\Delta_y}+\\sum_{j\\neq y}e^{z_j}}$ where $\\Delta_j = \\frac{C}{n_j^{1/4}}$ for $j\\in 1,2,3$\n",
    "- Hyperparameter C\n",
    "\n",
    "C is the hyperparameter we tuned by sweeping in different values. According to the paper and the GitHub provided by the paper, it represent the complexity of the dataset theoretically such that C could be normalised by the max number of data among the classes. However, since calculating the Rademacher complexity is complicated. Therefore, we try C with different values and found out C = 5 have a better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VUbXkDDiX9D6"
   },
   "outputs": [],
   "source": [
    "class BL2(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 C = 0,\n",
    "                 lr = 0.05,\n",
    "                 oversample=False,\n",
    "                 verbose = False\n",
    "                ):\n",
    "        super(BL2, self).__init__()\n",
    "        self.oversample = oversample\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "        self.C = C\n",
    "        self.cls_num_list = None #torch.empty(1, 3)\n",
    "        self.cls_weight_list = None #torch.empty(1, 3)\n",
    "        self.loss_func = nn.CrossEntropyLoss(weight = self.cls_weight_list)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(4, 3, 5)\n",
    "        self.resnet = models.resnet50(pretrained = True)\n",
    "        \n",
    "        # freeze all layers in resnet\n",
    "        for parameter in self.resnet.parameters():\n",
    "            parameter.requires_grad = False\n",
    "            \n",
    "        # redefine the last fc layer in resnet\n",
    "        #self.resnet.fc = nn.Linear(2048, 1024)\n",
    "        self.resnet.fc.requires_grad=True\n",
    "        \n",
    "        self.fc1 = nn.Linear(1000, 512)\n",
    "        self.fc2 = nn.Linear(512, 3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.resnet(x)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, target = batch\n",
    "        output = self.forward(images)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        acc = (target == preds).float().mean()\n",
    "        loss = self.LDAM(output,target)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc)\n",
    "        return {'loss': loss, 'acc': acc}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, target = batch\n",
    "        output = self.forward(images)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        acc = (target == preds).float().mean()\n",
    "        loss = self.LDAM(output,target)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc)\n",
    "        return {'loss': loss, 'acc': acc}\n",
    "\n",
    "    def cls_num_weight_list(self,state):\n",
    "        if state == 'train':\n",
    "            num_list = train_smallset.get_cls_num_list(train_folder) #Size : [1,class size]\n",
    "        elif state == 'test' or state == 'val':\n",
    "            num_list = val_set.get_cls_num_list(val_folder) #Size : [1,class size] \n",
    "\n",
    "        #cls_weight_list\n",
    "        beta = 0\n",
    "        effective_num = 1.0 - np.power(beta, num_list)\n",
    "        weight_list = (1.0 - beta) / np.array(effective_num)\n",
    "        weight_list = weight_list / np.sum(weight_list) * len(num_list)\n",
    "        weight_list = torch.FloatTensor(weight_list)       \n",
    "        #---------\n",
    "        self.cls_num_list = num_list\n",
    "        self.cls_weight_list = weight_list\n",
    "\n",
    "    def LDAM(self, before_m, target): # output Size : [batch size,class size] , target Size: [1,batch size]\n",
    "        #Initialization\n",
    "        C = self.C\n",
    "        cls_num_list = self.cls_num_list\n",
    "        \n",
    "        #LDAM\n",
    "        m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list)) #1/n_j^(1/4)\n",
    "        #print(m_list)\n",
    "        m_list = m_list * (C / np.max(m_list)) #Size : [1,3] source: m_list = m_list * (C / np.max(m_list))\n",
    "        m_list = torch.cuda.FloatTensor(m_list) #type change to tensor ,Size : [1,class size]\n",
    "        #print(m_list)\n",
    "        index = torch.zeros_like(before_m, dtype=torch.uint8) #create array ,Size : [batch size,class size]\n",
    "        #print('index before',index)\n",
    "        index.scatter_(1, target.data.view(-1, 1), 1)# one-hot of target, Size : [batch size,class size]\n",
    "        #print('target',target)    \n",
    "        #print('index after',index)    \n",
    "        index_float = index.type(torch.cuda.FloatTensor)# index type: int -> float Size : [batch size,class size]\n",
    "        batch_m = torch.matmul(m_list[None, :], index_float.transpose(0,1)) # m_list[1,class size] * index_float[class size,batch size] ,batch_m Size : [1,batch size]\n",
    "        #print('batch_m',batch_m)\n",
    "        batch_m = batch_m.view((-1, 1)) # Transpose Size : [batch size,1]\n",
    "        #print('batch_m',batch_m)\n",
    "        #print('Before',before_m) \n",
    "        x_m = before_m - batch_m  \n",
    "        \n",
    "        #print('x_m',x_m)  \n",
    "        after_m = torch.where(index, x_m, before_m) # replace z_y by z_y-delta_y only at the target class\n",
    "        #print('where',after_m)\n",
    "        #print('After',after_m - before_m) \n",
    "        #print(self.cls_weight_list)\n",
    "        return self.loss_func(after_m,target)\n",
    "\n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        loss_list = []\n",
    "        acc_list = []\n",
    "        for output in training_step_outputs:\n",
    "            loss_list.append(output[\"loss\"].item())\n",
    "            acc_list.append(output[\"acc\"].item())\n",
    "        if self.verbose:\n",
    "            print('train_loss:', sum(loss_list)/len(loss_list), 'train_acc:', sum(acc_list)/len(acc_list))\n",
    "        train_loss_plot.append(sum(loss_list)/len(loss_list))\n",
    "        train_acc_plot.append(sum(acc_list)/len(acc_list))\n",
    "        \n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        loss_list = []\n",
    "        acc_list = []\n",
    "        for output in validation_step_outputs:\n",
    "            loss_list.append(output[\"loss\"].item())\n",
    "            acc_list.append(output[\"acc\"].item())\n",
    "        if self.verbose:\n",
    "            print('        validation_loss:', sum(loss_list)/len(loss_list), 'validation_acc:', sum(acc_list)/len(acc_list))\n",
    "        val_loss_plot.append(sum(loss_list)/len(loss_list))\n",
    "        val_acc_plot.append(sum(acc_list)/len(acc_list))\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return optim.AdamW(self.parameters(), lr=self.lr,betas=(0.9,0.999),eps=1e-08,weight_decay=0,amsgrad=False)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        dataset = train_set\n",
    "        self.cls_num_weight_list('train')\n",
    "        if self.oversample:\n",
    "            return DataLoader(dataset, batch_size=40, num_workers=8, sampler=ImbalancedDatasetSampler(dataset))\n",
    "        else:\n",
    "            return DataLoader(dataset, batch_size=40, num_workers=8, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = val_set\n",
    "        self.cls_num_weight_list('val')\n",
    "        return DataLoader(dataset, batch_size=40, num_workers=8, shuffle=False)\n",
    "\n",
    "\n",
    "# model = BL2(lr=0.0002, verbose=False, oversample=False, C = C)\n",
    "# trainer = Trainer(\n",
    "#     gpus=1,\n",
    "#     progress_bar_refresh_rate = 20,\n",
    "#     callbacks=[EarlyStopping(\n",
    "#           monitor='val_loss',\n",
    "#           patience=30,\n",
    "#         min_delta=0.00,\n",
    "#         verbose=False\n",
    "#       )],\n",
    "#       num_sanity_val_steps=0\n",
    "# )\n",
    "# trainer.fit(model)\n",
    "# model.eval()\n",
    "\n",
    "model = torch.load('BL2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQ6UaMkXD-0Y"
   },
   "source": [
    "Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Covgb6gS4SnU"
   },
   "outputs": [],
   "source": [
    "evaluate(model, train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOAYcP4k4SnU"
   },
   "source": [
    "Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cG7HwfOM4PGX"
   },
   "outputs": [],
   "source": [
    "evaluate(model, val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Effect of LDAMLoss on the model*\n",
    "Before Application of LDAMLoss\n",
    "![dataaug](graphs/dataaugx3.jpeg)\n",
    "After Application of LDAMLoss\n",
    "![da](graphs/clsreport.jpeg)\n",
    "\n",
    "After Applying LDAMLoss, the training accuracy has dropped 2% but the validation accuracy increased 2%. This is because applying LDAMLoss reduced the prediction on class 1 which is the largest dataset and the no. of prediction on class2 has increased. However, since class 2 has less sample, the accuracy of correctly predicted class2 is lower than that of class 1, resulting in a lower overall accuracy. During validation, the precision on class 2 has greatly increased from 0.51 to 0.68. This imply the model predict class 2 a more frequently. the F1 score of class 2 increased from 62 to 69 contributed to the overall increase of validation accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7p06f3-KX9qu"
   },
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VMaBTnVYJoV"
   },
   "source": [
    "Observed Problem of baseline 1& 2:\n",
    "\n",
    "1. Imbalanced dataset\n",
    "2. Convergence with low accuracy in early epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6clBsyKaYB_E"
   },
   "source": [
    "Applied Techniques : \n",
    "\n",
    "1. Class Balanced Loss\n",
    "- $CB_{softmax}((x,y);f) = -\\frac{1-\\beta}{1-\\beta^{n_y}}log(\\frac{e^{z_y}}{\\sum_{j}e^{z_j}})$\n",
    "\n",
    "- weighting is introduced to the loss function\n",
    "- larger weight for smaller class and smaller weight for larger class\n",
    "- purpose: increase the error for smaller class to allow optimiser have a higher momentum towards \n",
    "2. Predicted output Scale up\n",
    "\n",
    "- Scaling up the output value by multiplying **30** ,  then the difference between predicted output and target will all linearly scaled up, therefore the optimiser will have more space to adapt the loss and update the parameters. Therefore, the loss at first several epochs will drop rapidly as the optimiser will have a more aggressive approach and less aggressive when the loss is reduced to a relatively smaller values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1-TrgCuYFzI"
   },
   "outputs": [],
   "source": [
    "class BL2(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 C = 0,\n",
    "                 lr = 0.05,\n",
    "                 oversample=False,\n",
    "                 verbose = False\n",
    "                ):\n",
    "        super(BL2, self).__init__()\n",
    "        self.oversample = oversample\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "        self.C = C\n",
    "        self.cls_num_list = None #torch.empty(1, 3)\n",
    "        self.cls_weight_list = None #torch.empty(1, 3)\n",
    "        self.loss_func = nn.CrossEntropyLoss(weight = self.cls_weight_list)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(4, 3, 5)\n",
    "        self.resnet = models.resnet50(pretrained = True)\n",
    "        \n",
    "        # freeze all layers in resnet\n",
    "        for parameter in self.resnet.parameters():\n",
    "            parameter.requires_grad = False\n",
    "            \n",
    "        # redefine the last fc layer in resnet\n",
    "        #self.resnet.fc = nn.Linear(2048, 1024)\n",
    "        self.resnet.fc.requires_grad=True\n",
    "        \n",
    "        self.fc1 = nn.Linear(1000, 512)\n",
    "        self.fc2 = nn.Linear(512, 3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.resnet(x)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, target = batch\n",
    "        output = self.forward(images)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        acc = (target == preds).float().mean()\n",
    "        loss = self.LDAM(output,target)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc)\n",
    "        return {'loss': loss, 'acc': acc}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, target = batch\n",
    "        output = self.forward(images)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        acc = (target == preds).float().mean()\n",
    "        loss = self.LDAM(output,target)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc)\n",
    "        return {'loss': loss, 'acc': acc}\n",
    "\n",
    "    def cls_num_weight_list(self,state):\n",
    "        if state == 'train':\n",
    "            num_list = train_smallset.get_cls_num_list(train_folder) #Size : [1,class size]\n",
    "        elif state == 'test' or state == 'val':\n",
    "            num_list = val_set.get_cls_num_list(val_folder) #Size : [1,class size] \n",
    "\n",
    "        #cls_weight_list\n",
    "        beta = 0\n",
    "        effective_num = 1.0 - np.power(beta, num_list)\n",
    "        weight_list = (1.0 - beta) / np.array(effective_num)\n",
    "        weight_list = weight_list / np.sum(weight_list) * len(num_list)\n",
    "        weight_list = torch.FloatTensor(weight_list)       \n",
    "        #---------\n",
    "        self.cls_num_list = num_list\n",
    "        self.cls_weight_list = weight_list\n",
    "\n",
    "    def LDAM(self, before_m, target): # output Size : [batch size,class size] , target Size: [1,batch size]\n",
    "        #Initialization\n",
    "        C = self.C\n",
    "        cls_num_list = self.cls_num_list\n",
    "        \n",
    "        #LDAM\n",
    "        m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list)) #1/n_j^(1/4)\n",
    "        #print(m_list)\n",
    "        m_list = m_list * (C / np.max(m_list)) #Size : [1,3] source: m_list = m_list * (C / np.max(m_list))\n",
    "        m_list = torch.cuda.FloatTensor(m_list) #type change to tensor ,Size : [1,class size]\n",
    "        #print(m_list)\n",
    "        index = torch.zeros_like(before_m, dtype=torch.uint8) #create array ,Size : [batch size,class size]\n",
    "        #print('index before',index)\n",
    "        index.scatter_(1, target.data.view(-1, 1), 1)# one-hot of target, Size : [batch size,class size]\n",
    "        #print('target',target)    \n",
    "        #print('index after',index)    \n",
    "        index_float = index.type(torch.cuda.FloatTensor)# index type: int -> float Size : [batch size,class size]\n",
    "        batch_m = torch.matmul(m_list[None, :], index_float.transpose(0,1)) # m_list[1,class size] * index_float[class size,batch size] ,batch_m Size : [1,batch size]\n",
    "        #print('batch_m',batch_m)\n",
    "        batch_m = batch_m.view((-1, 1)) # Transpose Size : [batch size,1]\n",
    "        #print('batch_m',batch_m)\n",
    "        #print('Before',before_m) \n",
    "        x_m = before_m - batch_m  \n",
    "        \n",
    "        #print('x_m',x_m)  \n",
    "        after_m = torch.where(index, x_m, before_m) # replace z_y by z_y-delta_y only at the target class\n",
    "        #print('where',after_m)\n",
    "        #print('After',after_m - before_m) \n",
    "        #print(self.cls_weight_list)\n",
    "        return self.loss_func(30*after_m,target)\n",
    "\n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        loss_list = []\n",
    "        acc_list = []\n",
    "        for output in training_step_outputs:\n",
    "            loss_list.append(output[\"loss\"].item())\n",
    "            acc_list.append(output[\"acc\"].item())\n",
    "        if self.verbose:\n",
    "            print('train_loss:', sum(loss_list)/len(loss_list), 'train_acc:', sum(acc_list)/len(acc_list))\n",
    "        train_loss_plot.append(sum(loss_list)/len(loss_list))\n",
    "        train_acc_plot.append(sum(acc_list)/len(acc_list))\n",
    "        \n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        loss_list = []\n",
    "        acc_list = []\n",
    "        for output in validation_step_outputs:\n",
    "            loss_list.append(output[\"loss\"].item())\n",
    "            acc_list.append(output[\"acc\"].item())\n",
    "        if self.verbose:\n",
    "            print('        validation_loss:', sum(loss_list)/len(loss_list), 'validation_acc:', sum(acc_list)/len(acc_list))\n",
    "        val_loss_plot.append(sum(loss_list)/len(loss_list))\n",
    "        val_acc_plot.append(sum(acc_list)/len(acc_list))\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return optim.AdamW(self.parameters(), lr=self.lr,betas=(0.9,0.999),eps=1e-08,weight_decay=0,amsgrad=False)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        dataset = train_set\n",
    "        self.cls_num_weight_list('train')\n",
    "        if self.oversample:\n",
    "            return DataLoader(dataset, batch_size=40, num_workers=8, sampler=ImbalancedDatasetSampler(dataset))\n",
    "        else:\n",
    "            return DataLoader(dataset, batch_size=40, num_workers=8, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = val_set\n",
    "        self.cls_num_weight_list('val')\n",
    "        return DataLoader(dataset, batch_size=40, num_workers=8, shuffle=False)\n",
    "\n",
    "\n",
    "  # model = BL2(lr=0.0002, verbose=False, oversample=False, C = C)\n",
    "  # trainer = Trainer(\n",
    "  #     gpus=1,\n",
    "  #     progress_bar_refresh_rate = 20,\n",
    "  #     callbacks=[EarlyStopping(\n",
    "  #           monitor='val_loss',\n",
    "  #           patience=30,\n",
    "  #         min_delta=0.00,\n",
    "  #         verbose=False\n",
    "  #       )],\n",
    "  #       num_sanity_val_steps=0\n",
    "  # )\n",
    "  # trainer.fit(model)\n",
    "  # model.eval()\n",
    "\n",
    "model = torch.load('model_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6P1bz-Ia4SnU"
   },
   "source": [
    "Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0XFFBsbD7vY"
   },
   "outputs": [],
   "source": [
    "evaluate(model, train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xrHZWRrEDYz"
   },
   "source": [
    "Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rr1PbHLsEFWi"
   },
   "outputs": [],
   "source": [
    "evaluate(model, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project_final_version.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
